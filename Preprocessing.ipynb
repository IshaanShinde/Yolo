{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a856b9b",
   "metadata": {},
   "source": [
    "# Video -> Images + Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36460f36",
   "metadata": {},
   "source": [
    "- Takes a video and a model.pt as the inputs\n",
    "- Saves all frames as images\n",
    "- Saves the images + annotations in a separate directory for frames where the model detected an object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22302b6",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1736f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac593df2",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb45b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = ''\n",
    "model_path = ''\n",
    "frames_folder = ''\n",
    "filtered_folder = ''\n",
    "confidence_threshold = 0.7\n",
    "iou_threshold = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672be3a",
   "metadata": {},
   "source": [
    "### Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if not exist\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "os.makedirs(filtered_folder, exist_ok=True)\n",
    "\n",
    "# Step 1: Extract frames from video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_id = 0\n",
    "\n",
    "print(\"[INFO] Extracting frames from video...\")\n",
    "with tqdm(total=total_frames, desc=\"Extracting Frames\") as pbar:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(frames_folder, f\"frame_{frame_id:05d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_id += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "cap.release()\n",
    "print(f\"[INFO] Extracted {frame_id} frames to '{frames_folder}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ae3c6",
   "metadata": {},
   "source": [
    "### Run the Model + Filter Frames + Save Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load model\n",
    "print(\"[INFO] Loading YOLO model...\")\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Step 3: Run detection on each frame and filter\n",
    "print(\"[INFO] Running detection and filtering frames...\")\n",
    "frame_files = sorted(os.listdir(frames_folder))\n",
    "filtered_count = 0\n",
    "\n",
    "for file_name in tqdm(frame_files, desc=\"Filtering Frames\"):\n",
    "    img_path = os.path.join(frames_folder, file_name)\n",
    "\n",
    "    results = model(img_path, conf=confidence_threshold, iou=iou_threshold)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    if detections is not None and len(detections) > 0:\n",
    "        if any(conf.item() >= confidence_threshold for conf in detections.conf):\n",
    "            save_path = os.path.join(filtered_folder, file_name)\n",
    "            cv2.imwrite(save_path, cv2.imread(img_path))\n",
    "            filtered_count += 1\n",
    "\n",
    "print(f\"\\nDone! {filtered_count} filtered frames saved to '{filtered_folder}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac60a07",
   "metadata": {},
   "source": [
    "# Crop + Center Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c157b49",
   "metadata": {},
   "source": [
    "- Finds the largest bounding box\n",
    "- Crops around the bunding box leaving a specified % of margin\n",
    "- Pads the image so that the margin is consistent wherever necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffd45c",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d570b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5cfc4",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af869561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yolo_label(label_path):\n",
    "    \"\"\"Read YOLO label file and return list of bounding boxes.\"\"\"\n",
    "    bboxes = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            bboxes.append({\n",
    "                'class_id': int(class_id),\n",
    "                'x_center': x_center,\n",
    "                'y_center': y_center,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "    return bboxes\n",
    "\n",
    "def find_largest_bbox(bboxes):\n",
    "    \"\"\"Find the bounding box with the largest area.\"\"\"\n",
    "    if not bboxes:\n",
    "        return None\n",
    "    areas = [bbox['width'] * bbox['height'] for bbox in bboxes]\n",
    "    return bboxes[np.argmax(areas)]\n",
    "\n",
    "def denormalize_bbox(bbox, img_width, img_height):\n",
    "    \"\"\"Convert normalized YOLO bbox to pixel coordinates.\"\"\"\n",
    "    x_center = bbox['x_center'] * img_width\n",
    "    y_center = bbox['y_center'] * img_height\n",
    "    width = bbox['width'] * img_width\n",
    "    height = bbox['height'] * img_height\n",
    "    x_min = x_center - width / 2\n",
    "    y_min = y_center - height / 2\n",
    "    x_max = x_center + width / 2\n",
    "    y_max = y_center + height / 2\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def calculate_crop_coords(x_min, y_min, x_max, y_max, img_width, img_height, padding_ratio=0.1):\n",
    "    \"\"\"Calculate crop coordinates with padding (20% of bbox dimensions), allowing extension beyond image.\"\"\"\n",
    "    bbox_width = x_max - x_min\n",
    "    bbox_height = y_max - y_min\n",
    "    padding_x = bbox_width * padding_ratio\n",
    "    padding_y = bbox_height * padding_ratio\n",
    "\n",
    "    # Calculate crop coordinates without clamping to image boundaries\n",
    "    crop_x_min = int(x_min - padding_x)\n",
    "    crop_x_max = int(x_max + padding_x)\n",
    "    crop_y_min = int(y_min - padding_y)\n",
    "    crop_y_max = int(y_max + padding_y)\n",
    "\n",
    "    return crop_x_min, crop_y_min, crop_x_max, crop_y_max\n",
    "\n",
    "def update_bboxes(bboxes, crop_x_min, crop_y_min, crop_width, crop_height, img_width, img_height):\n",
    "    \"\"\"Update bounding box annotations for the cropped image.\"\"\"\n",
    "    updated_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max = denormalize_bbox(bbox, img_width, img_height)\n",
    "        \n",
    "        # Check if bbox is within crop region\n",
    "        if x_max < crop_x_min or x_min > crop_x_min + crop_width or \\\n",
    "           y_max < crop_y_min or y_min > crop_y_min + crop_height:\n",
    "            continue\n",
    "\n",
    "        # Adjust bbox coordinates to cropped image\n",
    "        new_x_min = x_min - crop_x_min\n",
    "        new_y_min = y_min - crop_y_min\n",
    "        new_x_max = x_max - crop_x_min\n",
    "        new_y_max = y_max - crop_y_min\n",
    "\n",
    "        # Normalize to new image dimensions\n",
    "        new_x_center = (new_x_min + new_x_max) / 2 / crop_width\n",
    "        new_y_center = (new_y_min + new_y_max) / 2 / crop_height\n",
    "        new_width = (new_x_max - new_x_min) / crop_width\n",
    "        new_height = (new_y_max - new_y_min) / crop_height\n",
    "\n",
    "        # Ensure bbox is valid\n",
    "        if new_x_center >= 0 and new_x_center <= 1 and new_y_center >= 0 and new_y_center <= 1 and \\\n",
    "           new_width > 0 and new_height > 0:\n",
    "            updated_bboxes.append({\n",
    "                'class_id': bbox['class_id'],\n",
    "                'x_center': new_x_center,\n",
    "                'y_center': new_y_center,\n",
    "                'width': new_width,\n",
    "                'height': new_height\n",
    "            })\n",
    "    return updated_bboxes\n",
    "\n",
    "def save_updated_label(label_path, updated_bboxes, output_label_path):\n",
    "    \"\"\"Save updated YOLO annotations.\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_label_path), exist_ok=True)\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        for bbox in updated_bboxes:\n",
    "            f.write(f\"{bbox['class_id']} {bbox['x_center']:.6f} {bbox['y_center']:.6f} \"\n",
    "                    f\"{bbox['width']:.6f} {bbox['height']:.6f}\\n\")\n",
    "\n",
    "def process_split(data_dir, split, output_dir):\n",
    "    \"\"\"Process images and labels for a given split (train/val).\"\"\"\n",
    "    image_dir = os.path.join(data_dir, 'images', split)\n",
    "    label_dir = os.path.join(data_dir, 'labels', split)\n",
    "    output_image_dir = os.path.join(output_dir, 'cropped_images', split)\n",
    "    output_label_dir = os.path.join(output_dir, 'cropped_labels', split)\n",
    "\n",
    "    os.makedirs(output_image_dir, exist_ok=True)\n",
    "    os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of all images in the image_dir\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        # Corresponding label file path\n",
    "        label_file = image_name + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to read image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            # No label file: simply copy the image to output_image_dir\n",
    "            output_image_path = os.path.join(output_image_dir, image_file)\n",
    "            shutil.copy2(image_path, output_image_path)\n",
    "            print(f\"No label for {image_file}. Image copied without cropping.\")\n",
    "            continue\n",
    "\n",
    "        # Process images with labels as before\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        bboxes = read_yolo_label(label_path)\n",
    "        largest_bbox = find_largest_bbox(bboxes)\n",
    "\n",
    "        if not largest_bbox:\n",
    "            print(f\"No valid bounding boxes in {label_file}. Copying image as is.\")\n",
    "            # Copy image as is since no valid bbox\n",
    "            output_image_path = os.path.join(output_image_dir, image_file)\n",
    "            shutil.copy2(image_path, output_image_path)\n",
    "            # Save empty label file\n",
    "            output_label_path = os.path.join(output_label_dir, label_file)\n",
    "            with open(output_label_path, 'w') as f:\n",
    "                pass\n",
    "            continue\n",
    "\n",
    "        # Calculate crop coordinates\n",
    "        x_min, y_min, x_max, y_max = denormalize_bbox(largest_bbox, img_width, img_height)\n",
    "        crop_x_min, crop_y_min, crop_x_max, crop_y_max = calculate_crop_coords(\n",
    "            x_min, y_min, x_max, y_max, img_width, img_height\n",
    "        )\n",
    "\n",
    "        # Calculate crop dimensions\n",
    "        crop_width = crop_x_max - crop_x_min\n",
    "        crop_height = crop_y_max - crop_y_min\n",
    "\n",
    "        if crop_width <= 0 or crop_height <= 0:\n",
    "            print(f\"Invalid crop dimensions for {image_path}. Copying image as is.\")\n",
    "            output_image_path = os.path.join(output_image_dir, image_file)\n",
    "            shutil.copy2(image_path, output_image_path)\n",
    "            # Save empty label file\n",
    "            output_label_path = os.path.join(output_label_dir, label_file)\n",
    "            with open(output_label_path, 'w') as f:\n",
    "                pass\n",
    "            continue\n",
    "\n",
    "        # Create a black canvas for the cropped image\n",
    "        cropped_image = np.zeros((crop_height, crop_width, 3), dtype=np.uint8)\n",
    "\n",
    "        # Calculate the region of the original image that can be copied\n",
    "        src_x_min = max(0, crop_x_min)\n",
    "        src_y_min = max(0, crop_y_min)\n",
    "        src_x_max = min(img_width, crop_x_max)\n",
    "        src_y_max = min(img_height, crop_y_max)\n",
    "\n",
    "        # Calculate the corresponding region in the cropped image\n",
    "        dst_x_min = max(0, -crop_x_min)\n",
    "        dst_y_min = max(0, -crop_y_min)\n",
    "        dst_x_max = dst_x_min + (src_x_max - src_x_min)\n",
    "        dst_y_max = dst_y_min + (src_y_max - src_y_min)\n",
    "\n",
    "        # Copy the valid portion of the original image to the cropped image\n",
    "        if src_x_max > src_x_min and src_y_max > src_y_min:\n",
    "            cropped_image[dst_y_min:dst_y_max, dst_x_min:dst_x_max] = \\\n",
    "                image[src_y_min:src_y_max, src_x_min:src_x_max]\n",
    "\n",
    "        # Update bounding boxes\n",
    "        updated_bboxes = update_bboxes(\n",
    "            bboxes, crop_x_min, crop_y_min, crop_width, crop_height, img_width, img_height\n",
    "        )\n",
    "\n",
    "        # Save cropped image\n",
    "        output_image_path = os.path.join(output_image_dir, image_file)\n",
    "        cv2.imwrite(output_image_path, cropped_image)\n",
    "\n",
    "        # Save updated label\n",
    "        output_label_path = os.path.join(output_label_dir, label_file)\n",
    "        save_updated_label(label_path, updated_bboxes, output_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34652b2e",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02665dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = '/home/ishaan/Documents/AppRely/Repositories/ultralytics/data/2label_background'\n",
    "    output_dir = '/home/ishaan/Documents/AppRely/Repositories/ultralytics/data/2label_background_cropCentred'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "    # for split in ['test']:\n",
    "        print(f\"Processing {split} split...\")\n",
    "        process_split(data_dir, split, output_dir)\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9fa7d",
   "metadata": {},
   "source": [
    "# Blur Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904b222",
   "metadata": {},
   "source": [
    "- If an image has a resolution > 800x800 pixels\n",
    "- Fetches a kernel of an appropriate size based on the aspect ratio and resolution of the image\n",
    "- Applies Gaussian Blur with the fetched kernel size and saves the image to a new directory with the same structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1dfeb",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f9e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969594f",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241692c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure(src_root, dst_root):\n",
    "    \"\"\"Create the same directory structure in the destination as in the source.\"\"\"\n",
    "    # Ensure the destination root exists\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "    \n",
    "    # Create images and labels directories\n",
    "    os.makedirs(os.path.join(dst_root, \"images\", \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst_root, \"images\", \"val\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst_root, \"labels\", \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst_root, \"labels\", \"val\"), exist_ok=True)\n",
    "    \n",
    "    # Copy the data.yaml file\n",
    "    yaml_src = os.path.join(src_root, \"data.yaml\")\n",
    "    yaml_dst = os.path.join(dst_root, \"data.yaml\")\n",
    "    \n",
    "    if os.path.exists(yaml_src):\n",
    "        # Read the YAML file\n",
    "        with open(yaml_src, 'r') as file:\n",
    "            yaml_data = yaml.safe_load(file)\n",
    "        \n",
    "        # Update paths if necessary (optional)\n",
    "        if 'path' in yaml_data:\n",
    "            # Update the path to point to the new blurred data directory\n",
    "            yaml_data['path'] = str(Path(dst_root).resolve())\n",
    "        \n",
    "        # Write to the destination\n",
    "        with open(yaml_dst, 'w') as file:\n",
    "            yaml.dump(yaml_data, file, default_flow_style=False)\n",
    "    else:\n",
    "        print(f\"Warning: {yaml_src} not found. YAML file not copied.\")\n",
    "\n",
    "def checkBaseDimensions(image):\n",
    "    if image is None:\n",
    "        return False\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    if height <=800 or width <=800:\n",
    "        return False\n",
    "\n",
    "    return True    \n",
    "\n",
    "def fetchDynamicKernel(image):\n",
    "    height, width, channels = image.shape\n",
    "    aspect_ratio = width / height\n",
    "    kernel_width = int(width * 0.01 * max(1, aspect_ratio/2))\n",
    "    kernel_height = int(height * 0.01 * max(1, 2/aspect_ratio))\n",
    "    # Make both odd\n",
    "    if kernel_width % 2 == 0: kernel_width += 1\n",
    "    if kernel_height % 2 == 0: kernel_height += 1\n",
    "    kernel_size = (kernel_width, kernel_height)  # Non-square kernel\n",
    "\n",
    "    return kernel_size\n",
    "\n",
    "def apply_blur_to_images(src_root, dst_root):#, blur_kernel_size=(15, 15)):\n",
    "\n",
    "    # Process training images\n",
    "    train_src = os.path.join(src_root, \"images\", \"train\")\n",
    "    train_dst = os.path.join(dst_root, \"images\", \"train\")\n",
    "    \n",
    "    # Process validation images\n",
    "    val_src = os.path.join(src_root, \"images\", \"val\")\n",
    "    val_dst = os.path.join(dst_root, \"images\", \"val\")\n",
    "    \n",
    "    # Process both directories\n",
    "    for src_dir, dst_dir in [(train_src, train_dst), (val_src, val_dst)]:\n",
    "        if not os.path.exists(src_dir):\n",
    "            print(f\"Warning: Source directory {src_dir} does not exist. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing images in {src_dir}...\")\n",
    "        for img_file in os.listdir(src_dir):\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                src_path = os.path.join(src_dir, img_file)\n",
    "                dst_path = os.path.join(dst_dir, img_file)\n",
    "                \n",
    "                # Read the image\n",
    "                img = cv2.imread(src_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read {src_path}. Skipping.\")\n",
    "                    continue\n",
    "                if checkBaseDimensions(img) == False:\n",
    "                    print(f\"Warning: Image {src_path} has a low resolution. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                blur_kernel_size = fetchDynamicKernel(img)\n",
    "                print(blur_kernel_size)\n",
    "                print(\"\\n\\n\")\n",
    "\n",
    "                # Apply Gaussian blur\n",
    "                blurred_img = cv2.GaussianBlur(img, blur_kernel_size, 0)\n",
    "                \n",
    "                # Save the blurred image\n",
    "                cv2.imwrite(dst_path, blurred_img)\n",
    "                print(f\"Blurred and saved: {dst_path}\")\n",
    "\n",
    "def copy_label_files(src_root, dst_root):\n",
    "    \"\"\"Copy all label files from the source to the destination.\"\"\"\n",
    "    # Copy training labels\n",
    "    train_src = os.path.join(src_root, \"labels\", \"train\")\n",
    "    train_dst = os.path.join(dst_root, \"labels\", \"train\")\n",
    "    \n",
    "    # Copy validation labels\n",
    "    val_src = os.path.join(src_root, \"labels\", \"val\")\n",
    "    val_dst = os.path.join(dst_root, \"labels\", \"val\")\n",
    "    \n",
    "    # Process both directories\n",
    "    for src_dir, dst_dir in [(train_src, train_dst), (val_src, val_dst)]:\n",
    "        if not os.path.exists(src_dir):\n",
    "            print(f\"Warning: Source directory {src_dir} does not exist. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Copying labels from {src_dir}...\")\n",
    "        for label_file in os.listdir(src_dir):\n",
    "            if label_file.lower().endswith('.txt'):\n",
    "                src_path = os.path.join(src_dir, label_file)\n",
    "                dst_path = os.path.join(dst_dir, label_file)\n",
    "                \n",
    "                # Copy the label file\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                print(f\"Copied: {dst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bc1f0",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c154467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    src_data_dir = \"/home/ishaan/Documents/AppRely/Repositories/ultralytics/data/1label_background_cropCentred\"               # Source data directory\n",
    "    dst_data_dir = \"/home/ishaan/Documents/AppRely/Repositories/ultralytics/data/1label_background_cropCentred_blurred\"       # Destination data directory\n",
    "    # blur_kernel_size = (16, 17)         # Gaussian blur kernel size (width, height)\n",
    "    \n",
    "    # Create the destination directory structure\n",
    "    create_directory_structure(src_data_dir, dst_data_dir)\n",
    "    \n",
    "    # Apply blur to all images\n",
    "    apply_blur_to_images(src_data_dir, dst_data_dir)#, blur_kernel_size)\n",
    "    \n",
    "    # Copy all label files\n",
    "    copy_label_files(src_data_dir, dst_data_dir)\n",
    "    \n",
    "    print(f\"\\nDone! Blurred dataset created at {dst_data_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
